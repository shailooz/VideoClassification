{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.convolutional import Conv3D,MaxPooling3D\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras import Sequential\n",
    "from keras.optimizers import SGD,RMSprop,Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import sklearn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = []\n",
    "YY = []\n",
    "j=0\n",
    "base_path=\"../dataset/videos\"\n",
    "source_path=base_path\n",
    "for child in os.listdir(source_path):\n",
    "    print(child)\n",
    "    sub_path = os.path.join(source_path, child)\n",
    "    bsub_path = os.path.join(base_path, child)\n",
    "    if os.path.isdir(sub_path):\n",
    "        for data_file in os.listdir(sub_path):\n",
    "            path=os.path.join(bsub_path,data_file)\n",
    "            print(path)\n",
    "            frames=[]\n",
    "            cap=cv2.VideoCapture(path)\n",
    "            fcount=cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "            num_frames = 1000\n",
    "            loop_limit = int(min(num_frames,fcount))\n",
    "            print(\"Capturing {0} frames\".format(num_frames))\n",
    "\n",
    "            for i in range(0, loop_limit) :\n",
    "                ret, frame = cap.read()\n",
    "                gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "                resized=cv2.resize(gray, (224,224), interpolation = cv2.INTER_AREA)\n",
    "                frames.append(resized)\n",
    "\n",
    "            last_frame= frames[-1]\n",
    "            for i in range(loop_limit, num_frames):\n",
    "                frames.append(last_frame)\n",
    "            XX.append(frames)\n",
    "            print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "\n",
    "            cap.release()\n",
    "            YY.append(child)\n",
    "print(np.shape(XX))\n",
    "print(np.shape(YY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.reshape(XX,(27,224,224,1000,-1))\n",
    "print(np.shape(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.reshape(YY,(-1,1))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer\n",
    "oh=OneHotEncoder()\n",
    "y=oh.fit_transform(y)\n",
    "lb=LabelBinarizer()\n",
    "Y=lb.fit_transform(y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(Y))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv3D(128,(7,7,7),input_shape=(224,224,1000,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(3,3,3)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(64,(3,3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(3,3,3),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(25))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "history=model.fit(X_train,y_train,epochs=1000,callbacks=[checkpoint],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
